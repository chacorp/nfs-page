<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Neural Face Skinning for Mesh-agnostic Facial Expression Cloning">
  <meta name="keywords" content="Neural Skinning, Expression Cloning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Neural Face Skinning for Mesh-agnostic Facial Expression Cloning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/ICT_face_segment.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Neural Face Skinning for Mesh-agnostic Facial Expression Cloning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://chacorp.github.io/sihuncha/">Sihun Cha</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://vml.kaist.ac.kr/main/people/person/193">Serin Yoon</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://seokg.github.io/">Kwanggyoon Seo</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://vml.kaist.ac.kr/main/people/person/1">Junyong Noh</a><sup>1</sup>,</span>
          </div>
          
          <br/>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup><a href="https://vml.kaist.ac.kr/home">Visual Media Lab</a>, KAIST, Republic of Korea</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>2</sup><a href="https://www.flawlessai.com/">Flawless AI</a>, United States of America</span>
          </div>
          
          <br/>
          
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><b>Eurographics 2025</b></span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-light">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <span class="link-block">
                <!-- <a href="https://arxiv.org/pdf/2305.00936.pdf"
                   class="external-link button is-normal is-rounded is-dark"> -->
                <a href=""
                   class="external-link button is-normal is-rounded is-light">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>ArXiv</span>
                </a>
              </span>
              
              <span class="link-block">
                <a href="https://github.com/chacorp/NFS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img class="round" style="width:1024px" src="static/images/teaser.png"/>
      <h2 class="subtitle has-text-centered">
        We present a method that enables direct retargeting between two facial meshes with different shapes and mesh structures.
      </h2>
    </div>
  </div>
</section>




  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Accurately retargeting facial expressions to a face mesh while enabling manipulation is a key challenge in 
            facial animation retargeting. Recent deep-learning methods address this by encoding facial expressions into a global latent code, but they often fail to capture fine-grained details in local regions. While some methods improve local accuracy by transferring deformations locally, this often complicates overall control of the facial expression. To address this, we propose a method that combines the strengths of both global and local deformation models. Our approach enables intuitive control and detailed expression cloning across diverse face meshes, regardless of their underlying structures. The core idea is to localize the influence of the global latent code on the target mesh. Our model learns to predict skinning weights for each vertex of the target face mesh through indirect supervision from predefined segmentation labels. These predicted weights localize the global latent code, enabling precise and region-specific deformations even for meshes with unseen shapes. We supervise the latent code using Facial Action Coding System (FACS)-based blendshapes to ensure interpretability and allow straightforward editing of the generated animation. Through extensive experiments, we demonstrate improved performance over state-of-the-art methods in terms of expression fidelity, deformation transfer accuracy, and adaptability across diverse mesh structures.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Key idea</h2>
      <p></p>
    </div>
    <div class="columns is-centered">
      <img class="round" style="width:960px" src="static/images/concept.png"/>
      <p></p>      
    </div>

    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        Brief illustration of the key idea.
      </h2>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            Our method localizes the influence of global expression on the local regions in the target mesh by utilizing per-vertex skinning weights, 
            enabling precise expression cloning on the local region.
          </p>
        </div>
      </div>
    </div>
    
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Overview</h2>
      <p></p>
    </div>

    <div class="columns is-centered">
      <img class="round" style="width:960px" src="static/images/method_overview.png"/>
      <p></p>
    </div>
    
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Illustration of the data flow at inference (a) and training (b). 
          For simplicity, the encoders are omitted from (b) and the dotted red box indicates the losses that are exclusively applied to the ICT data. 
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            For the training, we utilize the synthetic data created by using the ICT-Facekit and the real data from the Multiface dataset for the training.
            During the training, we supervise identity and expression encoders using ICT blendshape.
          </p>
          <p>
            In addition to identity and expression encoders, we employ a skinning encoder to predict the per-vertex skinning weight from the target mesh.
            The skinning weight is used to localize the global expression code.
            Given the localized expression code, the decoder outputs the local deformation, which deforms the target mesh. 
          </p>
        </div>
      </div>
    </div>
    
    <br/><br/><br/>
    
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Supervision using the segmentation</h2>
      <p></p>
    </div>

    <br/>
    
    <div class="columns is-centered">
      <img class="round" style="width:640px" src="static/images/predefined segment.png"/>
      <p></p>
    </div>

    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        Segmentation label for ICT face mesh.
      </h2>
    </div>
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>          
            A key aspect of our method is predicting the skinning weights that capture the relationship between local regions and the global expression code. 
          </p>
          <p>
            However, we cannot directly supervise the model with skinning weight as blendshape face models do not utilize skinning weights.
            To address this, we supervise the skinning encoder using a predefined segmentation label.
          </p>
          <p>
            This indirect supervision aims to regularize the skinning encoder by ensuring consistent skinning weights for corresponding face regions across different face shapes.
            While the skinning encoder can converge without this supervision, the estimated weights may lack the desired consistency.
          </p>
        </div>
      </div>
    </div>

    <br/>

    <div class="columns is-centered">
      <img class="round" style="width:960px" src="static/images/segment_prediction.png"/>
      <p></p>
    </div>
    
    <br/>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Visualization of face skinning weight on the ICT face mesh and various unseen meshes. 
          We extracted the maximum value in z_Skin for each vertex and calculated the mode value on each triangle for the rendering.
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          To supervise the skinning encoder using the segmentation labels, we created a segmentation map that divides the face into several regions based on ICT by referring to the facial muscle group.
          We do not force z_Skin to take a strict one-hot form, allowing for some degrees of spatial correlation to remain during training.
          The supervision is applied exclusively when the training data is obtained from ICT. 
        </div>
      </div>
    </div>
    
  </div>
</section>

  

  
<section class="section">
  <div class="container is-max-desktop">

    <!-- Experiments. -->
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Experiments</h2>
      </div>
    </div>
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          To evaluate the expression quality, we conducted a self-retargeting task in which the model retargets a face mesh with an expression to the same mesh in a neutral expression.
          We also conducted experiments on inverse rigging to validate if our constructed expression code conforms to the grammar of the FACS-based ICT blendshape model.
        </div>
      </div>
    </div>

    <br/><br/>
    
    
    <div class="columns is-centered has-text-centered">
      <iframe src="https://drive.google.com/file/d/15Vh5VALXaiTQCj6bLmieTY00iF6xVlR_/preview" 
      onload='javascript:(function(o){o.style.width=o.contentWindow.document.body.parentElement.scrollWidth+"px";}(this))' 
      allow="autoplay; controls; loop"></iframe>
    </div>
    
    <br/>
    
    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        ICT with unseen IDs and expressions (randomly sampled blendshapes)
      </h2>
    </div>
    
    <br/><br/><br/><br/>

    <div class="columns is-centered has-text-centered">
      <iframe src="https://drive.google.com/file/d/1qC6lk2kV1FymLrQb8HdfE8worvscHy8D/preview"
      onload='javascript:(function(o){o.style.width=o.contentWindow.document.body.parentElement.scrollWidth+"px";}(this))' 
      allow="autoplay; controls; loop"></iframe>
    </div>

    <br/>

    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        ICT with unseen IDs and expressions (captured using LiveLink App)
      </h2>
    </div>

    <br/><br/><br/><br/>

    <div class="columns is-centered has-text-centered">
      <iframe src="https://drive.google.com/file/d/1ImneF_19L8nI7Enwhm4nHkp_m4CFZBdE/preview" 
      onload='javascript:(function(o){o.style.width=o.contentWindow.document.body.parentElement.scrollWidth+"px";}(this))' 
      allow="autoplay; controls; loop"></iframe>
    </div>

    <br/>

    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        Multiface with unseen ID and expressions (EXP_free_face)
      </h2>
    </div>

    <br/><br/><br/><br/>

    <div class="columns is-centered has-text-centered">
      <iframe src="https://drive.google.com/file/d/1XNWWHjAS0-P9FH241KutyiFPVjuwMir-/preview" 
      onload='javascript:(function(o){o.style.width=o.contentWindow.document.body.parentElement.scrollWidth+"px";}(this))' 
      allow="autoplay; controls; loop"></iframe>
    </div>

    <br/>

    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        Expression cloning on stylized face mesh
      </h2>
    </div>
    
    <br/><br/><br/><br/>
    <!-- Experiments. -->

    
    <!-- Editing. -->
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Application</h2>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <iframe src="https://drive.google.com/file/d/1CN1Db1O2emDCaYWR2rl5_qkfJTZdJXhM/preview" onload='javascript:(function(o){o.style.width=o.contentWindow.document.body.parentElement.scrollWidth+"px";}(this))' allow="autoplay; controls; loop"></iframe>
    </div>
    <br/>

    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        Editing expressions
      </h2>
    </div>

    <!-- <br/> -->
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Limitation</h2>
      </div>
    </div>
    
    <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        One of the limitations is that the editability is bound to the ICT blendshape which cannot handle head pose and neck movement.
        Another limitation arises from the skinning encoder as the quality of expression cloning drops when the skinning weight prediction is inaccurate.
        Additionally, jittering sometimes occurred as shown in the videos. Integrating a temporal module would be a potential direction for future work.
      </h2>
    </div>

    <!-- <div class="columns is-centered">
      <h2 class="subtitle has-text-centered">
        Editing
      </h2>
    </div> -->
    
    <br/><br/><br/><br/>
    
  
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          Please refer to the paper for more details!
        </div>
      </div>
    </div>


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>



<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @article {10.1111:cgf.14769,
    journal = {Computer Graphics Forum},
    title = {{Generating Texture for 3D Human Avatar from a Single Image using Sampling and Refinement Networks}},
    author = {Cha, Sihun and Seo, Kwanggyoon and Ashtari, Amirsaman and Noh, Junyong},
    year = {2023},
    publisher = {The Eurographics Association and John Wiley & Sons Ltd.},
    ISSN = {1467-8659},
    DOI = {10.1111/cgf.14769}
    }
    </code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">

    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website code is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            We thank the authors for sharing the templates.
          </p>
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
